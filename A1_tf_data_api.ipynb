{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data API\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.range(10)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "\n",
    "## no overlapping\n",
    "dataset = dataset.batch(2)\n",
    "\n",
    "## overlapping\n",
    "dataset = dataset.window(2, shift = 1, drop_remainder = True) # create an overlapping window of 2, nested dataset\n",
    "dataset = dataset.flat_map(lambda ds: ds.batch(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1]\n",
      " [2 3]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[4 5]\n",
      " [6 7]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[6 7]\n",
      " [8 9]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset.repeat(3).batch(7) #dup 3 times then make into batches of 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset2:\n",
    "    print(item)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map, Apply, Filter\n",
    "\n",
    "The map, apply, filter functions can be used similarly as other libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset2.map(lambda x: x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset3 = dataset2.apply(tf.data.experimental.unbatch())\n",
    "\n",
    "for item in dataset3:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset3 = dataset3.filter(lambda x: x > 10)\n",
    "for item in dataset3.take(3): print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 3 6 7 9 4 5 0 1], shape=(10,), dtype=int64)\n",
      "tf.Tensor([1 8 6 5 4 8 7 1 2 3], shape=(10,), dtype=int64)\n",
      "tf.Tensor([0 5 4 2 7 8 9 9 3 6], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size = 5, seed = 42).batch(10) # create a buffer of 5, fill buffer randomly until filled, then repat\n",
    "for item in dataset: print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interleaving Data Sets\n",
    "\n",
    "For large datasets, it may not be possible to load all in memory, one method is to choose a number of files randomly then interleave the records.\n",
    "\n",
    "sample code below (will not work)\n",
    "\n",
    "For interleaving to work best, it is preferable that the files to have identical lenght."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dataset = tf.data.Dataset.list_files(train_file_paths, seed = 43)\n",
    "\n",
    "n_readers = 5\n",
    "\n",
    "dataset = filepath_dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1), cycle_length = n_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.list_files(\"./*.ipynb\", seed = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'.\\\\4_unstable_gradient_problem.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\A1_tf_data_api-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\9.1_auto_diff.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\2_tensor_board.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\vae-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\regression.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\keras_mnist.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\0_keras_classification.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\7_learning_rate_scheduling-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\9_custom_models-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\9.1_auto_diff-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\vae.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\8_regularisation-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\0_keras_classification-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\5_transfer_learning-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\3_hyperparameter_tuning.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\1.2_keras_callbacks.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\1_keras_regression.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\1_keras_regression-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\keras_mnist-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\basics.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\5_transfer_learning.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\7_learning_rate_scheduling.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\9_custom_models.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\A1_tf_data_api.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\regression-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\catsdogs.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\8_regularisation.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\6_optimisers.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\1.1_keras_complex_model.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\4_unstable_gradient_problem-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\6_optimisers-checkpoint.ipynb', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\.ipynb_checkpoints\\\\2_tensor_board-checkpoint.ipynb', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in ds: print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# test_size is default to 0.25\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean = np.mean(X_train, axis = 0)\n",
    "std = np.std(X_train, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.89076345e+00,  2.84118863e+01,  5.45071779e+00,  1.09953883e+00,\n",
       "         1.42615650e+03,  3.05288363e+00,  3.56371568e+01, -1.19574169e+02]),\n",
       " array([1.91674877e+00, 1.25751637e+01, 2.77494120e+00, 5.51820330e-01,\n",
       "        1.07561370e+03, 1.15602144e+01, 2.13787119e+00, 2.00433468e+00]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in tensorflow/A1_tf_data_api.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 52d93d8] initial checkin\n",
      " 1 file changed, 219 insertions(+), 1 deletion(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/auslei/python.git\n",
      "   a187270..52d93d8  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git add A1_tf_data_api.ipynb\n",
    "!git commit -m \"initial checkin\"\n",
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_with_tf",
   "language": "python",
   "name": "ml_with_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
