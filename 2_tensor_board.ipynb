{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__, keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up log location\n",
    "\n",
    "To use tensorboard, you must modify your program to output files for visualisation to special binary log files called *event files*. Each binary data record is called *summary*. \n",
    "\n",
    "Tensorboard service will monitor root log directory and automatically update visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\tf_logs\\2020_09_22-20_49_44\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"tf_logs\")\n",
    "\n",
    "def run_logdir():\n",
    "    root_logdir = os.path.join(os.curdir, \"tf_logs\")\n",
    "    run_id = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "\n",
    "print(run_logdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Fashion mnist dataroot_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(X_train_full.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation Data Set\n",
    "\n",
    "Also in addition to that do a very basic scaling (ie. dividing data by 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28) (5000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid  = X_train_full[5000:] / 255.0, X_train_full[:5000] / 255.0\n",
    "y_train, y_valid  = y_train_full[5000:], y_train_full[:5000]\n",
    "\n",
    "print(X_train.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/pop\", \"Trouser\", \"Pullover\", \"Dresss\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() # remove all previous weights\n",
    "tf.random.set_seed(1234) # set same seeds\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(300, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both statements are the same\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Callback Functions for TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_begin` time: 0.0200s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.5150s). Check your callbacks.\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 200\n",
    "history = model.fit(X_train, y_train, epochs=NUM_EPOCHS, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    verbose = False, callbacks = [tensorboard_cb])\n",
    "#history = model.fit(X_train_full, y_train_full, epochs=NUM_EPOCHS, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from Jupyter\n",
    "\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./tf_logs --port=6006\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower Level API\n",
    "\n",
    "Additionally, TensorFlow offers a lower-level API in the **tf.summary** package, where we can log scalars, histograms, images, audio, and text. All of which can be visualised with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_logdir = \"./tf_log_file_write_example\"\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step/10), step = step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 #some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets = 50, step = step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # random 32x32 RGB image\n",
    "        tf.summary.image(\"my_images\", images *step/1000, step = step)\n",
    "        texts = [f\"The step is {step}\", f\"it's square is {step**2}\"]\n",
    "        tf.summary.text(\"my_text\", texts, step = step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 *np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate = 48000, step = step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_with_tf",
   "language": "python",
   "name": "ml_with_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
